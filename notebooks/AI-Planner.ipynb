{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfb47729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found data at: D:\\Projects\\Projects Collection\\Final Year Project\\Charoo\\AI Powered Guide for Sustainabe Tourism Prediction\\data\\ecotourism_dataset.csv\n",
      "üîÑ Loading Ecotourism Dataset...\n",
      "‚úÖ Encoders saved.\n",
      "‚úÖ Processed data saved to processed_data.csv\n",
      "   Features: ['Visitor_Age', 'Visit_Type', 'Travel_Purpose', 'Eco_Rating', 'Service_Quality', 'Crowd_Level', 'Expense_Level', 'Eco_Activity_Count']\n",
      "   Target: Sentiment_Label\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_FILENAME = \"ecotourism_dataset.csv\"\n",
    "PROCESSED_DATA_PATH = \"processed_data.csv\"\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- SMART PATH DETECTION ---\n",
    "# We check multiple locations to find where the file is hiding\n",
    "possible_paths = [\n",
    "    Path(DATA_FILENAME),              # Current directory\n",
    "    Path(\"data\") / DATA_FILENAME,     # data/ folder\n",
    "    Path(\"../data\") / DATA_FILENAME,  # Parent data folder\n",
    "    Path(\"notebooks/data\") / DATA_FILENAME # Notebooks data folder\n",
    "]\n",
    "\n",
    "DATA_FILE = None\n",
    "for path in possible_paths:\n",
    "    if path.exists():\n",
    "        DATA_FILE = path\n",
    "        print(f\"‚úÖ Found data at: {path.resolve()}\")\n",
    "        break\n",
    "\n",
    "if DATA_FILE is None:\n",
    "    print(\"‚ùå Error: Could not find 'ecotourism_dataset.csv'.\")\n",
    "    print(\"   Please make sure you have downloaded the file and placed it in your project folder.\")\n",
    "    print(f\"   Checked locations: {[p.name for p in possible_paths]}\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "print(\"üîÑ Loading Ecotourism Dataset...\")\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# --- CLEANING ---\n",
    "# We will predict 'Sentiment_Label' based on user features\n",
    "target_col = \"Sentiment_Label\"\n",
    "feature_cols = [\n",
    "    \"Visitor_Age\", \"Visit_Type\", \"Travel_Purpose\", \n",
    "    \"Eco_Rating\", \"Service_Quality\", \"Crowd_Level\", \n",
    "    \"Expense_Level\", \"Eco_Activity_Count\"\n",
    "]\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "df = df.dropna(subset=feature_cols + [target_col])\n",
    "\n",
    "# --- ENCODING ---\n",
    "encoders = {}\n",
    "for col in [\"Visit_Type\", \"Travel_Purpose\", \"Crowd_Level\", \"Expense_Level\"]:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# Encode Target\n",
    "target_le = LabelEncoder()\n",
    "df[target_col] = target_le.fit_transform(df[target_col])\n",
    "encoders[\"target\"] = target_le\n",
    "\n",
    "# Save Encoders for the App\n",
    "joblib.dump(encoders, MODEL_DIR / \"encoders.pkl\")\n",
    "print(\"‚úÖ Encoders saved.\")\n",
    "\n",
    "# Save Processed Data\n",
    "final_df = df[feature_cols + [target_col]]\n",
    "final_df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "print(f\"‚úÖ Processed data saved to {PROCESSED_DATA_PATH}\")\n",
    "print(f\"   Features: {feature_cols}\")\n",
    "print(f\"   Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe95a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Training & Evaluating models...\n",
      "   Random Forest CV Mean: 33.49% | Test Acc: 35.83%\n",
      "   Logistic Regression CV Mean: 35.99% | Test Acc: 36.46%\n",
      "üèÜ Best Model Selected: Logistic Regression\n",
      "‚úÖ Models and Cross-Validation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "# --- CONFIG ---\n",
    "DATA_FILENAME = \"processed_data.csv\"\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- PATH DETECTION ---\n",
    "if Path(DATA_FILENAME).exists():\n",
    "    DATA_PATH = Path(DATA_FILENAME)\n",
    "else:\n",
    "    print(\"‚ùå Processed data not found. Run 01_process_data.py first.\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- LOAD ---\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "X = df.drop(columns=[\"Sentiment_Label\"])\n",
    "y = df[\"Sentiment_Label\"]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- TRAINING WITH CROSS-VALIDATION ---\n",
    "print(\"ü§ñ Training & Evaluating models...\")\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model 1: Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_cv_scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "print(f\"   Random Forest CV Mean: {rf_cv_scores.mean():.2%} | Test Acc: {rf_test_acc:.2%}\")\n",
    "\n",
    "# Model 2: Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_cv_scores = cross_val_score(lr, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "lr.fit(X_train, y_train)\n",
    "lr_test_acc = accuracy_score(y_test, lr.predict(X_test))\n",
    "print(f\"   Logistic Regression CV Mean: {lr_cv_scores.mean():.2%} | Test Acc: {lr_test_acc:.2%}\")\n",
    "\n",
    "# --- SELECTION (Based on Test Accuracy) ---\n",
    "if rf_test_acc >= lr_test_acc:\n",
    "    best_model = rf\n",
    "    best_name = \"Random Forest\"\n",
    "    best_acc = rf_test_acc\n",
    "else:\n",
    "    best_model = lr\n",
    "    best_name = \"Logistic Regression\"\n",
    "    best_acc = lr_test_acc\n",
    "\n",
    "print(f\"üèÜ Best Model Selected: {best_name}\")\n",
    "\n",
    "# --- SAVE ARTIFACTS ---\n",
    "joblib.dump(best_model, MODEL_DIR / \"best_model.pkl\")\n",
    "\n",
    "# Save Metrics for App\n",
    "metrics = {\n",
    "    \"accuracy\": best_acc,\n",
    "    \"rf_acc\": rf_test_acc,\n",
    "    \"lr_acc\": lr_test_acc,\n",
    "    \"rf_cv\": rf_cv_scores.mean(),\n",
    "    \"lr_cv\": lr_cv_scores.mean(),\n",
    "    \"best_model\": best_name,\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, best_model.predict(X_test)).tolist()\n",
    "}\n",
    "joblib.dump(metrics, MODEL_DIR / \"model_metrics.pkl\")\n",
    "print(\"‚úÖ Models and Cross-Validation metrics saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
